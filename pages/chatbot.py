'''
    ì±—ë´‡ í˜ì´ì§€ ì½”ë“œ
        - ai_res_typeìœ¼ë¡œ ì¼ë°˜ ì±—ë´‡ê³¼ ì¦ìƒ ì±—ë´‡ì„ êµ¬ë¶„í•¨.
'''
import streamlit as st
from dotenv import load_dotenv
import os
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain.agents import AgentExecutor, load_tools, create_openai_tools_agent
from langchain.memory import ConversationBufferMemory
from langchain import hub
from llama_index.core import StorageContext, load_index_from_storage
from llama_index.core.callbacks.base import CallbackManager
#ì‚¬ì´ë“œë°” ë¡œê·¸ì¸
from components.sidebar import sidebar


load_dotenv()
ai_res_type = 0

st.title("ğŸ’¬ ê°•ì•„ì§€ ì¦ìƒ ì „ë¬¸ ì±—ë´‡")

# í† ê¸€ë²„íŠ¼ì„ í†µí•´ ì¦ìƒ ì±—ë´‡ í™œì„±í™”/ë¹„í™œì„±í™” -> í™œì„±í™”ë©´ ai_res_type = 1, ë¹„í™œì„±í™”ë©´ ai_res_type = 0
# ìµœëŒ€í•œ ì˜¤ë¥¸ìª½ì— ë°°ì¹˜
st.toggle("ì¦ìƒ ì±—ë´‡ í™œì„±í™”", value=False, key="symptom_chatbot")
if st.session_state.symptom_chatbot:
    ai_res_type = 1

def chatbot():
    # íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ê°ì²´ ìƒì„±
    history = StreamlitChatMessageHistory()

    # ì´ì „ ëŒ€í™” ë‚´ìš© ë Œë”ë§
    for message in history.messages:
        st.chat_message(message.type).write(message.content)

    # ì‚¬ìš©ì ì…ë ¥
    prompt = st.chat_input('ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?')
    if prompt:
        st.session_state.symptom_prompt = prompt
        # ì‚¬ìš©ì ì…ë ¥ ì¶œë ¥ ë° íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        with st.chat_message('user'):
            st.markdown(prompt)
            history.add_user_message(prompt)

        # ì§ˆì˜ ê°€ê³µ
        formatted_prompt = f'''
        {prompt}
        ì˜ì‹¬ë˜ëŠ” ì¦ìƒëª… 3ê°€ì§€ ì•Œë ¤ì¤˜. 
        ë˜í•œ, ê° ì¦ìƒëª…ì— ëŒ€í•œ ì¦ìƒì„¤ëª…ì„ í•´ì¤˜.
        ì•„ë˜ í˜•ì‹ê³¼ ê°™ì´ ì‘ë‹µì„ ì¤˜.

        < ì˜ˆì‹œ >
        1. ì¦ìƒëª… - ì¦ìƒì„¤ëª…  
        2. ì¦ìƒëª… - ì¦ìƒì„¤ëª…  
        3. ì¦ìƒëª… - ì¦ìƒì„¤ëª…  
        '''
        
        # LlamaIndex ì¿¼ë¦¬ ìˆ˜í–‰
        s_context = StorageContext.from_defaults(persist_dir='index_db_backup')
        loaded_index = load_index_from_storage(s_context)
        loaded_query_engine = loaded_index.as_query_engine()
        response = loaded_query_engine.query(formatted_prompt)

        # ì‘ë‹µ ì¶œë ¥ ë° íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        with st.chat_message('assistant'):
            st.markdown(response.response)
            history.add_ai_message(response.response)


def init_chat():
    prompt = st.chat_input('ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?')
    history = StreamlitChatMessageHistory()
    for message in history.messages:
        st.chat_message(message.type).write(message.content)

    if prompt:  
        with st.chat_message('user'):  
            history.add_user_message(prompt)
            st.markdown(prompt)

        with st.chat_message('assistant'):
            cb = StreamlitCallbackHandler(st.container())
            agent_chain = init_agent_chain(history)
            res = agent_chain.invoke(
                {"input": prompt},   
                {"callbacks": [cb]}  
            )
            history.add_ai_message(res['output'])
            st.markdown(res['output'])
            pass



def init_agent_chain(history):
    llm = ChatOpenAI(
        model_name=os.environ['OPENAI_API_MODEL'],
        temperature=os.environ['OPENAI_API_TEMPERATURE']
    )
    tools = load_tools(["wikipedia"])
    hub_tool = hub.pull('hwchase17/openai-tools-agent')
    memory = ConversationBufferMemory(
        chat_memory=history,
        memory_key='my_first_chat',
        return_messages=True
    )
    agent = create_openai_tools_agent(llm, tools, hub_tool)
    return AgentExecutor(agent=agent, tools=tools, memory=memory)



sidebar()
if ai_res_type == 1:
    chatbot()
else:
    init_chat()
