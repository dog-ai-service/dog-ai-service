# ui
import streamlit as st
# íˆìŠ¤í† ë¦¬- ë‹¨ê¸°ê¸°ì–µ ì¬í˜„ - ëŒ€í™” ë‚´ìš© ìœ ì§€
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
# ë­ì²´ì¸ + openai ê´€ë ¨ ë¡œë“œ
from langchain_openai import ChatOpenAI
# Gptì—ê²Œ ì „ë‹¬í•  ì‚¬ìš©ì ë©”ì„¸ì§€ í¬ë§· ë¡œë“œ
from langchain.schema import HumanMessage
# ì„¤ì • : ai ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
from services.login_api import ai_res_type

from agents.init_agent import init_agent_chain
from langchain.callbacks import StreamlitCallbackHandler


#ì§ˆë¬¸ì°½
def prompt_box():
    prompt = st.chat_input('ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?')
    print(prompt)
    # íˆìŠ¤í† ë¦¬ ì²˜ë¦¬ -> ê¸°ì–µ -> ë­ì²´ì¸(ë‹¨ê¸°ê¸°ì–µ) or ë°±í„°ë””ë¹„(ì¥ê¸°ê¸°ì–µ)
    history = StreamlitChatMessageHistory()
    # ëŒ€í™” ë‚´ì—­ ì¶œë ¥ -> ë°˜ë³µ
    for message in history.messages:
        # ë©”ì„¸ì§€ ìœ í˜•( ì‚¬ìš©ì í˜¹ì€ ai(ì–´ì‹œìŠ¤í„´ìŠ¤) ) + ë©”ì„¸ì§€ í˜•íƒœ
        st.chat_message(message.type).write(message.content)

    # ì±„íŒ…(ë´‡) ì°½ì— ë©”ì„¸ì§€ ì„¸íŒ…
    # promptê°€ ì¡´ì¬í•˜ë©´
    if prompt:  # ë­”ê°€ë¥¼ ì…ë ¥í–ˆë‹¤
        with st.chat_message('user'):  # ì¼ë°˜ ìœ ì €ì˜ ì•„ì´ì½˜ìœ¼ë¡œ ì±„íŒ…ì°½ì— ë©”ì„¸ì§€ ì„¸íŒ…ë˜ëŠ” í‘œì‹
            # íˆìŠ¤í† ë¦¬ì— ì‚¬ìš©ì ë©”ì„¸ì§€(í”„ëŸ¼í”„íŠ¸) ì €ì¥
            history.add_user_message(prompt)
            # ì‚¬ìš©ì ë©”ì„¸ì§€ë¥¼ í‘œê¸°
            st.markdown(prompt)

        with st.chat_message('assistant'):
            # aiì˜ ì‘ë‹µ ; openai | openai + ìœ„í‚¤í”¼ë””ì•„ +  ê¸°íƒ€ ê²€ìƒ‰ì—”ì§„ë“± ì¦ê°•í•˜ì—¬
            if ai_res_type == 2:    # openai + ìœ„í‚¤í”¼ë””ì•„ +  ê¸°íƒ€ ê²€ìƒ‰ì—”ì§„ë“± ì¦ê°•í•˜ì—¬ ë‹µë³€
                # 1. ì½œë°± êµ¬ì„±
                cb = StreamlitCallbackHandler(st.container())
                # 2. ë­ì²´ì¸ ì—ì´ì „íŠ¸ êµ¬ì„± -> íˆìŠ¤í† ë¦¬ ì „ë‹¬ -> ëŒ€í™” ë‚´ìš©ì„ ì „ë‹¬(ê¸°ì–µ)
                agent_chain = init_agent_chain(history)
                # 3. ì—ì´ì „íŠ¸ ì´ìš©í•˜ì—¬ llm ì§ˆì˜
                res = agent_chain.invoke(
                    {"input": prompt},   # ì‚¬ìš©ìì˜ ì§ˆì˜
                    {"callbacks": [cb]}  # ì‘ë‹µ ì‘ì„±ì¤‘ì— ë¡œê·¸->í™”ë©´ í‘œê¸°ë“±ë“± ì—°ì¶œ
                )
                # 4. ì‘ë‹µ -> íˆìŠ¤í† ë¦¬ ë“±ë¡
                history.add_ai_message(res['output'])
                # 5. ê²°ê³¼ ì¶œë ¥
                st.markdown(res['output'])
                pass
            elif ai_res_type == 1:  # openaië¡œë§Œ ë‹µë³€
                # 1. GPT ì²˜ë¦¬í• ìˆ˜ ìˆëŠ” ChatOpenAI ê°ì²´ ìƒì„±
                llm = ChatOpenAI(
                    model_name=os.environ['OPENAI_API_MODEL'],
                    temperature=os.environ['OPENAI_API_TEMPERATURE']
                )
                # 2. í”„ëŸ¼í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (ì„œë¹„ìŠ¤ ì»¨ì…‰ ë¶€ì—¬ ê°€ëŠ¥) ì—¬ê¸°ì„œëŠ” íœ´ë¨¼ë©”ì„¸ì§€êµ¬ì„±
                msg = [HumanMessage(content=prompt)]
                # 4. GPT ìš”ì²­ -> ì½œë°± ì²˜ë¦¬ í•¨ìˆ˜ëŠ” ë‹¤ë¦„(ì—ì´ì „íŠ¸ì—ì„œ ì²˜ë¦¬)
                res = llm.invoke(msg)
                # 5. ì‘ë‹µ ë„ì°©, íˆìŠ¤í† ë¦¬ì— ë‹´ê¸°
                print(res.content)
                history.add_ai_message(res.content)
                # 6. í™”ë©´ ì„¸íŒ…
                st.markdown(res.content)
                pass
            else:  # ë”ë¯¸ ì‘ë‹µ
                st.markdown('ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š')